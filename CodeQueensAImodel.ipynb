{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmObpAWj5BHQGHE1IaoQgN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RosetheOnly/codequeens-AI-model/blob/main/CodeQueensAImodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community requests==2.32.4\n"
      ],
      "metadata": {
        "id": "Jip5srqDsuwo",
        "outputId": "4c56653b-d5a4-4583-927a-f6604842f923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Collecting requests==2.32.4\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (2025.8.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.28-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests, langchain-community\n",
            "\u001b[2K  Attempting uninstall: requests\n",
            "\u001b[2K    Found existing installation: requests 2.32.5\n",
            "\u001b[2K    Uninstalling requests-2.32.5:\n",
            "\u001b[2K      Successfully uninstalled requests-2.32.5\n",
            "\u001b[2K  Attempting uninstall: langchain-community\n",
            "\u001b[2K    Found existing installation: langchain-community 0.3.29\n",
            "\u001b[2K    Uninstalling langchain-community-0.3.29:\n",
            "\u001b[2K      Successfully uninstalled langchain-community-0.3.29\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [langchain-community]\n",
            "\u001b[1A\u001b[2KSuccessfully installed langchain-community-0.3.27 requests-2.32.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_906zb4brxvR",
        "outputId": "57f844e1-2d67-433c-ed92-6292e607c37c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "\u001b[2K  Attempting uninstall: requests\n",
            "\u001b[2K    Found existing installation: requests 2.32.4\n",
            "\u001b[2K    Uninstalling requests-2.32.4:\n",
            "\u001b[2K      Successfully uninstalled requests-2.32.4\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [langchain-community]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlL7Emz5AzKp",
        "outputId": "917f43f2-7d26-4081-cfb3-8f2ef194dbe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Synthetic M-Pesa transaction data saved to 'synthetic_mpesa_transactions.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from faker import Faker\n",
        "import random\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# 1. Generate classification data\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=5,\n",
        "    n_informative=3,\n",
        "    n_redundant=0,\n",
        "    n_classes=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2. Create DataFrame\n",
        "df = pd.DataFrame(X, columns=[\n",
        "    'amount_log',       # Will be converted to actual M-Pesa amount\n",
        "    'balance_change',\n",
        "    'time_since_last',\n",
        "    'merchant_score',\n",
        "    'location_score'\n",
        "])\n",
        "df['Is_Fraud'] = y\n",
        "\n",
        "# 3. Add user info\n",
        "users = [f'USER_{i+1}' for i in range(10)]\n",
        "df['Account'] = np.random.choice(users, size=1000)\n",
        "\n",
        "# 4. Simulate timestamps\n",
        "timestamps = pd.date_range(\n",
        "    start='2025-07-01',\n",
        "    periods=1000,\n",
        "    freq='2min'\n",
        ")\n",
        "df['Date'] = np.random.choice(timestamps, size=1000)\n",
        "\n",
        "# 5. Convert amount_log to realistic values\n",
        "df['Transaction_Amount'] = (10 ** df['amount_log'].clip(-1, 4)).astype(int)\n",
        "\n",
        "# 6. Add transaction types\n",
        "transaction_types = ['Send Money', 'Buy Goods', 'Pay Bill', 'Withdraw', 'Deposit']\n",
        "df['Transaction_Type'] = np.random.choice(transaction_types, size=1000)\n",
        "\n",
        "# 7. Add recipient phone numbers\n",
        "df['Recipient_Number'] = [fake.phone_number() for _ in range(1000)]\n",
        "\n",
        "# 8. Compute running balance per user\n",
        "df = df.sort_values(['Account', 'Date'])\n",
        "df['Wallet_Impact'] = df['balance_change'] * df['Transaction_Amount'] / 100\n",
        "df['Wallet_Impact'] = df['Wallet_Impact'].round(2)\n",
        "\n",
        "# Simulate starting balance and compute running balance\n",
        "df['Balance'] = df.groupby('Account')['Wallet_Impact'].cumsum() + 1000  # start with 1000 KES\n",
        "\n",
        "# 9. Final cleanup\n",
        "final_cols = [\n",
        "    'Account', 'Date', 'Transaction_Type', 'Transaction_Amount',\n",
        "    'Wallet_Impact', 'Balance', 'Recipient_Number', 'Is_Fraud'\n",
        "]\n",
        "df_final = df[final_cols].sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# 10. Save to CSV\n",
        "df_final.to_csv('synthetic_mpesa_transactions.csv', index=False)\n",
        "\n",
        "print(\"✅ Synthetic M-Pesa transaction data saved to 'synthetic_mpesa_transactions.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoDEbp3SbeBV",
        "outputId": "f0c20e20-e7a7-4d7e-da5b-3ec56a6fe8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suWi14aHcYoC",
        "outputId": "90d706a6-679d-42d1-a599-5b71112ab8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain\n"
      ],
      "metadata": {
        "id": "4PHmxQHYlOVh",
        "outputId": "1711d308-2f59-47b8-b62f-9dbaa9341c41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4467b866",
        "outputId": "dd3bc94d-b2ff-4eed-d763-9a2f23d1fa08"
      },
      "source": [
        "%pip install faker -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import timedelta\n",
        "\n",
        "# Initialize\n",
        "fake = Faker()\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Configuration\n",
        "users = [f'USER_{i+1}' for i in range(10)]\n",
        "months = pd.date_range(start='2024-08-01', periods=12, freq='MS')\n",
        "providers = {\n",
        "    'KPLC': {'unit': 'kWh', 'min': 30, 'max': 450, 'rate': 22.0},\n",
        "    'Nairobi Water': {'unit': 'm³', 'min': 5, 'max': 50, 'rate': 80.0}\n",
        "}\n",
        "\n",
        "records = []\n",
        "\n",
        "for user in users:\n",
        "    phone = fake.phone_number()\n",
        "    for month in months:\n",
        "        for provider, config in providers.items():\n",
        "            units = round(np.random.uniform(config['min'], config['max']), 1)\n",
        "            base = units * config['rate']\n",
        "            fee = np.random.uniform(50, 150)\n",
        "            total = round(base + fee, 2)\n",
        "\n",
        "            # Simulate billing and payment dates\n",
        "            billing_date = pd.to_datetime(month)\n",
        "            due_date = billing_date + pd.Timedelta(days=14)\n",
        "            actual_pay_date = due_date + pd.Timedelta(days=random.choice([0, 0, 2, 5, 10]))  # most pay on time\n",
        "\n",
        "            # Determine if late\n",
        "            was_late = actual_pay_date > due_date\n",
        "            penalty = round(total * 0.05, 2) if was_late else 0.00\n",
        "            final_amount = round(total + penalty, 2)\n",
        "\n",
        "            # Simulate M-Pesa payment\n",
        "            mpesa_code = fake.bothify(text='???###??')\n",
        "            mpesa_time = actual_pay_date + timedelta(hours=random.randint(1, 8))\n",
        "\n",
        "            records.append({\n",
        "                'User_ID': user,\n",
        "                'Provider': provider,\n",
        "                'Billing_Date': billing_date.date(),\n",
        "                'Due_Date': due_date.date(),\n",
        "                'Units_Used': units,\n",
        "                'Unit_Type': config['unit'],\n",
        "                'Total_Bill_KSh': total,\n",
        "                'Was_Late': was_late,\n",
        "                'Penalty_KSh': penalty,\n",
        "                'Final_Amount_KSh': final_amount,\n",
        "                'Paid_On': actual_pay_date.date(),\n",
        "                'M-Pesa_Code': mpesa_code.upper(),\n",
        "                'Phone_Number': phone,\n",
        "                'Payment_Time': mpesa_time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "            })\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('utility_bills_with_mpesa.csv', index=False)\n",
        "print(\"✅ CSV with M-Pesa confirmations and penalties saved as 'utility_bills_with_mpesa.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6xC4ZBsBXlO",
        "outputId": "e39b78c1-751c-4709-b83d-1ead7f15d2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV with M-Pesa confirmations and penalties saved as 'utility_bills_with_mpesa.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the utility bill data from the CSV into a DataFrame\n",
        "try:\n",
        "    utility_df = pd.read_csv('utility_bills_with_mpesa.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'utility_bills_with_mpesa.csv' not found. Please ensure the file is generated.\")\n",
        "    utility_df = pd.DataFrame() # Create an empty DataFrame to avoid further errors\n",
        "\n",
        "print(\"utility_bill_with_mpesa columns:\", utility_df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd6ew-5hBnhF",
        "outputId": "2b0d7385-b2d2-442f-a2f1-0f01356c44f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utility_bill_with_mpesa columns: ['User_ID', 'Provider', 'Billing_Date', 'Due_Date', 'Units_Used', 'Unit_Type', 'Total_Bill_KSh', 'Was_Late', 'Penalty_KSh', 'Final_Amount_KSh', 'Paid_On', 'M-Pesa_Code', 'Phone_Number', 'Payment_Time']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D3wqhEbqCNmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "ulzQ-42OeKWJ",
        "outputId": "304e0828-ed2e-4027-e1ab-a1476bf7e2fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Warning: No transactions extracted for account 7890-1234-5678-9012.\n",
            "Warning: No transactions extracted for account 5678-9012-3456-7890.\n",
            "Warning: No transactions extracted for account 6789-0123-4567-8901.\n",
            "Warning: No transactions extracted for account 4567-8901-2345-6789.\n",
            "Warning: No transactions extracted for account 3456-7890-1234-5678.\n",
            "Warning: No transactions extracted for account 9012-3456-7890-1234.\n",
            "Warning: No transactions extracted for account 8901-2345-6789-0123.\n",
            "Warning: No transactions extracted for account 2345-6789-0123-4567.\n",
            "Warning: No transactions extracted for account 0123-4567-8901-2345.\n",
            "Warning: No transactions extracted for account 1234-5678-9012-3456.\n",
            "Warning: bank_df is empty. PDF parsing may have failed.\n",
            "Warning: Bank data is empty. Combined dataframe contains only MPESA and Utility Bill data.\n",
            "✅ Combined data saved to '/content/combined_financial_data.csv'\n",
            "\n",
            "Combined DataFrame head:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4170840862.py:218: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  merged_initial = pd.concat([mpesa_clean, bills_clean], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Account_Number       Date    Description   Amount  Balance   Source_Type\n",
              "0         USER_1 2024-08-01  nairobi water  3298.96      NaN  UTILITY_BILL\n",
              "1         USER_8 2024-08-01  nairobi water  2271.97      NaN  UTILITY_BILL\n",
              "2         USER_8 2024-08-01           kplc  9119.22      NaN  UTILITY_BILL\n",
              "3         USER_5 2024-08-01           kplc  9548.40      NaN  UTILITY_BILL\n",
              "4         USER_5 2024-08-01  nairobi water  1708.92      NaN  UTILITY_BILL"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb5652ef-c162-4275-8295-1225710c812f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Account_Number</th>\n",
              "      <th>Date</th>\n",
              "      <th>Description</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Balance</th>\n",
              "      <th>Source_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>USER_1</td>\n",
              "      <td>2024-08-01</td>\n",
              "      <td>nairobi water</td>\n",
              "      <td>3298.96</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UTILITY_BILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>USER_8</td>\n",
              "      <td>2024-08-01</td>\n",
              "      <td>nairobi water</td>\n",
              "      <td>2271.97</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UTILITY_BILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>USER_8</td>\n",
              "      <td>2024-08-01</td>\n",
              "      <td>kplc</td>\n",
              "      <td>9119.22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UTILITY_BILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>USER_5</td>\n",
              "      <td>2024-08-01</td>\n",
              "      <td>kplc</td>\n",
              "      <td>9548.40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UTILITY_BILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>USER_5</td>\n",
              "      <td>2024-08-01</td>\n",
              "      <td>nairobi water</td>\n",
              "      <td>1708.92</td>\n",
              "      <td>NaN</td>\n",
              "      <td>UTILITY_BILL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb5652ef-c162-4275-8295-1225710c812f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb5652ef-c162-4275-8295-1225710c812f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb5652ef-c162-4275-8295-1225710c812f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cee5b456-f3e2-4f0d-ae40-1487f3dc7850\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cee5b456-f3e2-4f0d-ae40-1487f3dc7850')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cee5b456-f3e2-4f0d-ae40-1487f3dc7850 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"     print(\\\"Error: Combined DataFrame is empty after processing\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Account_Number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"USER_1\",\n          \"USER_8\",\n          \"USER_5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-08-01 00:00:00\",\n        \"max\": \"2024-08-01 00:00:00\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2024-08-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"kplc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3828.9446462804863,\n        \"min\": 1708.92,\n        \"max\": 9548.4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2271.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined DataFrame columns:\n",
            "['Account_Number', 'Date', 'Description', 'Amount', 'Balance', 'Source_Type']\n"
          ]
        }
      ],
      "source": [
        "# 🛠️ Step 1: Install Required Libraries\n",
        "!pip install pandas PyMuPDF\n",
        "\n",
        "# 📦 Step 2: Import Libraries\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "import fitz  # PyMuPDF for PDF parsing\n",
        "\n",
        "# 📁 Step 3: Mount Google Drive (if your files are there)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# 📂 Step 4: Set Paths to Your Files (update if needed)\n",
        "mpesa_csv = '/content/synthetic_mpesa_transactions.csv'\n",
        "bills_csv = '/content/utility_bills_with_mpesa.csv'\n",
        "bank_zip = '/content/fwdmockbankstatements.zip'\n",
        "extract_dir = '/content/unzipped_pdfs'\n",
        "\n",
        "# 📤 Step 5: Extract Bank Statements from ZIP\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(bank_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Define the bank statement parsing function (corrected from BWA3Kxh_ZOl0)\n",
        "def improved_parse_bank_statement_text(text):\n",
        "    \"\"\"\n",
        "    Parses text from a bank statement PDF to extract transaction data.\n",
        "    Now includes logic to extract Account Number and handle varied formats.\n",
        "    \"\"\"\n",
        "    transactions = []\n",
        "    account_number = \"Unknown\"\n",
        "\n",
        "    # Extract Account Number (Handling different possible patterns)\n",
        "    acct_match1 = re.search(r'Account Number:\\s*([\\d\\-]+)', text)\n",
        "    acct_match2 = re.search(r'Account:\\s*([\\d\\-]+)', text)\n",
        "    if acct_match1:\n",
        "        account_number = acct_match1.group(1).strip()\n",
        "    elif acct_match2:\n",
        "        account_number = acct_match2.group(1).strip()\n",
        "\n",
        "    # Find the start of the transactions table (Handling different possible headers)\n",
        "    # Look for 'Date', 'Description', 'Debit', 'Credit', 'Balance' or similar combinations\n",
        "    # Updated header pattern based on debug output and previous attempts\n",
        "    # Using \\s+ to match one or more whitespace characters, and potentially include newlines\n",
        "    header_pattern = re.compile(r'Date\\s+Description\\s+Details\\s+Debit\\s+\\(KES\\)\\s+Credit\\s+\\(KES\\)\\s+Balance\\s+\\(KES\\)', re.IGNORECASE)\n",
        "    header_match = header_pattern.search(text)\n",
        "\n",
        "    transaction_text = \"\"\n",
        "    if header_match:\n",
        "        transaction_text = text[header_match.end():]\n",
        "    else:\n",
        "        # Fallback: If header not found, try to find patterns of transaction lines\n",
        "        # This is less reliable and may pick up non-transaction lines\n",
        "        print(f\"Warning: Could not find transaction header in document for account {account_number}. Attempting to parse lines.\")\n",
        "        transaction_text = text # Use the whole text and rely on line parsing regex\n",
        "\n",
        "\n",
        "    # Regex to find transaction lines (adjust based on observed patterns)\n",
        "    # This regex is based on the structure seen in the debug output: Date, Description, Details, Debit, Credit, Balance\n",
        "    # It needs to be flexible to handle varying spaces and missing Debit/Credit values.\n",
        "    # Assuming Date format DD/MM/YYYY\n",
        "    # Making whitespace handling more flexible with \\s* and handling potential missing columns more robustly\n",
        "    transaction_line_pattern = re.compile(\n",
        "        r'^(\\d{2}/\\d{2}/\\d{4})\\s*'  # Date (Group 1) - flexible whitespace\n",
        "        r'(.*?)\\s+'               # Description (Group 2 - non-greedy match for anything, followed by one or more spaces)\n",
        "        r'(.*?)\\s*'               # Details (Group 3 - non-greedy match for anything, followed by zero or more spaces)\n",
        "        r'([\\d,\\.]*)\\s*'          # Debit (Group 4 - includes comma and dot, optional, followed by zero or more spaces)\n",
        "        r'([\\d,\\.]*)\\s*'          # Credit (Group 5 - includes comma and dot, optional, followed by zero or more spaces)\n",
        "        r'([\\d,\\.]+)\\s*$', re.MULTILINE # Balance (Group 6 - includes comma and dot, optional trailing spaces, end of line)\n",
        "    )\n",
        "\n",
        "\n",
        "    # Process text line by line\n",
        "    lines = transaction_text.strip().split('\\n')\n",
        "    for line in lines:\n",
        "         match = transaction_line_pattern.search(line)\n",
        "         if match:\n",
        "              date_str, description, details, debit_str, credit_str, balance_str = match.groups()\n",
        "\n",
        "              # Clean and convert numeric values\n",
        "              debit = float(debit_str.replace(',', '')) if debit_str and debit_str.strip() else 0.0\n",
        "              credit = float(credit_str.replace(',', '')) if credit_str and credit_str.strip() else 0.0\n",
        "              balance = float(balance_str.replace(',', '')) if balance_str and balance_str.strip() else 0.0\n",
        "\n",
        "              transactions.append({\n",
        "                  'Account_Number': account_number,\n",
        "                  'Date': pd.to_datetime(date_str, format='%d/%m/%Y', errors='coerce'),\n",
        "                  'Description': f\"{description.strip()} - {details.strip()}\".strip(' -'), # Combine description and details\n",
        "                  'Debit': debit,\n",
        "                  'Credit': credit,\n",
        "                  'Balance': balance\n",
        "              })\n",
        "\n",
        "\n",
        "    if not transactions:\n",
        "        print(f\"Warning: No transactions extracted for account {account_number}.\")\n",
        "        return pd.DataFrame() # Return empty DataFrame if no transactions found\n",
        "\n",
        "\n",
        "    return pd.DataFrame(transactions)\n",
        "\n",
        "\n",
        "\n",
        "# ✅ Step 6: Clean MPESA Transactions\n",
        "mpesa = pd.read_csv(mpesa_csv)\n",
        "mpesa.drop_duplicates(inplace=True)\n",
        "# Removed string operations from numeric columns\n",
        "mpesa['Transaction_Amount'] = mpesa['Transaction_Amount'].astype(float)\n",
        "mpesa['Balance'] = mpesa['Balance'].astype(float)\n",
        "# Removed string operation from Wallet_Impact\n",
        "# mpesa['Wallet_Impact'] = mpesa['Wallet_Impact'].str.lower().str.strip() # Wallet_Impact is numeric\n",
        "mpesa['Date'] = pd.to_datetime(mpesa['Date'], errors='coerce')\n",
        "mpesa['Source_Type'] = 'MPESA'\n",
        "# Rename 'Account' to 'Account_Number' for consistency before merging\n",
        "if 'Account' in mpesa.columns:\n",
        "    mpesa.rename(columns={\"Account\": \"Account_Number\"}, inplace=True)\n",
        "\n",
        "\n",
        "# ✅ Step 7: Clean Utility Bills\n",
        "bills = pd.read_csv(bills_csv)\n",
        "bills.dropna(subset=['Final_Amount_KSh'], inplace=True)\n",
        "bills['Final_Amount_KSh'] = bills['Final_Amount_KSh'].astype(float)\n",
        "# Assuming 'Provider' column is intended as the description and is string type\n",
        "if 'Provider' in bills.columns:\n",
        "    # bills['Bill_Type'] = bills['Bill_Type'].str.lower().str.strip() # Renamed to Description below\n",
        "    bills.rename(columns={'Provider': 'Description'}, inplace=True) # Renaming Provider to Description\n",
        "    if pd.api.types.is_object_dtype(bills['Description']) or pd.api.types.is_string_dtype(bills['Description']):\n",
        "         bills['Description'] = bills['Description'].astype(str).str.lower().str.strip()\n",
        "    else:\n",
        "         print(\"Warning: 'Description' column in utility bills is not a string type. Skipping string cleaning.\")\n",
        "\n",
        "bills['Date'] = pd.to_datetime(bills['Billing_Date'], errors='coerce').dt.date # Using Billing_Date as the Date for utility bills\n",
        "# Assuming Balance_After is not present or needs to be calculated later\n",
        "# bills.rename(columns={'Final_Amount_KSh': 'Amount', 'Balance_After': 'Balance', 'Bill_Type': 'Description'}, inplace=True)\n",
        "bills.rename(columns={'Final_Amount_KSh': 'Amount'}, inplace=True)\n",
        "bills['Source_Type'] = 'UTILITY_BILL'\n",
        "# Rename 'User_ID' to 'Account_Number' for consistency before merging\n",
        "if 'User_ID' in bills.columns:\n",
        "    bills.rename(columns={\"User_ID\": \"Account_Number\"}, inplace=True)\n",
        "\n",
        "\n",
        "# ✅ Step 8: Parse Bank PDFs (Using the corrected parsing logic from BWA3Kxh_ZOl0)\n",
        "# Replicating the parsing loop here for a self-contained cell\n",
        "all_data = []\n",
        "if os.path.exists(extract_dir):\n",
        "    for fname in os.listdir(extract_dir):\n",
        "        if fname.endswith(\".pdf\"):\n",
        "            doc_path = os.path.join(extract_dir, fname)\n",
        "            try:\n",
        "                doc = fitz.open(doc_path)\n",
        "                text = \"\"\n",
        "                for page in doc:\n",
        "                    text += page.get_text()\n",
        "                # Assuming improved_parse_bank_statement_text takes text as input and returns a DataFrame\n",
        "                df = improved_parse_bank_statement_text(text) # Need to pass account number if extracted separately\n",
        "                if not df.empty:\n",
        "                    all_data.append(df)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {fname}: {e}\")\n",
        "\n",
        "if all_data:\n",
        "    bank_df = pd.concat(all_data, ignore_index=True)\n",
        "    bank_df['Source_Type'] = 'BANK_STATEMENT'\n",
        "    # Ensure 'Date' column in bank_df is datetime\n",
        "    if 'Date' in bank_df.columns and not pd.api.types.is_datetime64_any_dtype(bank_df['Date']):\n",
        "        bank_df['Date'] = pd.to_datetime(bank_df['Date'], errors='coerce') # Keep as datetime for merging\n",
        "\n",
        "else:\n",
        "    bank_df = pd.DataFrame()\n",
        "    print(\"Warning: bank_df is empty. PDF parsing may have failed.\")\n",
        "\n",
        "\n",
        "# ✅ Step 9: Combine All Sources\n",
        "\n",
        "# Ensure common columns exist and have appropriate names before merging\n",
        "common_cols_initial = ['Account_Number', 'Date', 'Description', 'Amount', 'Balance', 'Source_Type']\n",
        "\n",
        "# Select and rename columns for merging\n",
        "mpesa_clean = mpesa[mpesa.columns.intersection(['Account_Number', 'Date', 'Transaction_Type', 'Transaction_Amount', 'Balance', 'Source_Type'])].copy()\n",
        "mpesa_clean.rename(columns={'Transaction_Type': 'Description', 'Transaction_Amount': 'Amount'}, inplace=True)\n",
        "mpesa_clean = mpesa_clean[common_cols_initial].copy() # Reindex to ensure consistent column order and drop extras\n",
        "\n",
        "\n",
        "bills_clean = bills[bills.columns.intersection(['Account_Number', 'Date', 'Description', 'Amount', 'Source_Type'])].copy()\n",
        "# Bills data doesn't have a 'Balance' column directly equivalent to account balance\n",
        "bills_clean['Balance'] = None # Add a placeholder Balance column\n",
        "# Ensure Date is datetime for merging consistency\n",
        "if 'Date' in bills_clean.columns and not pd.api.types.is_datetime64_any_dtype(bills_clean['Date']):\n",
        "    bills_clean['Date'] = pd.to_datetime(bills_clean['Date'], errors='coerce')\n",
        "bills_clean = bills_clean[common_cols_initial].copy() # Reindex\n",
        "\n",
        "\n",
        "# Ensure bank_df has the expected columns if populated\n",
        "bank_clean_merge = pd.DataFrame() # Initialize as empty\n",
        "if not bank_df.empty:\n",
        "    bank_clean = bank_df[bank_df.columns.intersection(['Account_Number', 'Date', 'Description', 'Debit', 'Credit', 'Balance', 'Source_Type'])].copy()\n",
        "\n",
        "    # Create 'Amount' from Debit/Credit for merging purposes\n",
        "    # Use Credit as positive amount (inflow), Debit as negative amount (outflow)\n",
        "    bank_clean['Amount'] = bank_clean['Credit'].fillna(0) - bank_clean['Debit'].fillna(0)\n",
        "\n",
        "    # Select columns for bank_clean for merging\n",
        "    bank_clean_merge = bank_clean[['Account_Number', 'Date', 'Source_Type', 'Amount', 'Balance', 'Description']].copy()\n",
        "    # Ensure Date is datetime for merging\n",
        "    if 'Date' in bank_clean_merge.columns and not pd.api.types.is_datetime64_any_dtype(bank_clean_merge['Date']):\n",
        "         bank_clean_merge['Date'] = pd.to_datetime(bank_clean_merge['Date'], errors='coerce')\n",
        "    # Ensure Account_Number exists (should be present if parsing worked)\n",
        "    if 'Account_Number' not in bank_clean_merge.columns:\n",
        "         print(\"Error: 'Account_Number' column is missing in bank_clean_merge after processing. Cannot merge.\")\n",
        "         bank_clean_merge = pd.DataFrame() # Make it empty to prevent merge errors\n",
        "\n",
        "\n",
        "# Perform Merges\n",
        "# Concatenate mpesa and bills first\n",
        "merged_initial = pd.concat([mpesa_clean, bills_clean], ignore_index=True)\n",
        "\n",
        "# Now merge with bank data only if bank_clean_merge is not empty\n",
        "if not bank_clean_merge.empty:\n",
        "    # Ensure date columns are datetime before merging\n",
        "    if 'Date' in merged_initial.columns and not pd.api.types.is_datetime64_any_dtype(merged_initial['Date']):\n",
        "         merged_initial['Date'] = pd.to_datetime(merged_initial['Date'], errors='coerce')\n",
        "    # bank_clean_merge['Date'] should already be datetime from steps above\n",
        "\n",
        "    # Perform an outer merge on Account_Number and Date\n",
        "    # Using suffixes to distinguish columns from merged_initial and bank_clean_merge\n",
        "    combined = pd.merge(merged_initial, bank_clean_merge, on=['Account_Number', 'Date', 'Source_Type'], how='outer', suffixes=('_other', '_bank'))\n",
        "\n",
        "    # Consolidate columns, prioritizing bank data where available\n",
        "    # Handle cases where suffixes might not exist if one side of merge had no data for a given Account_Number/Date/Source_Type combination\n",
        "    combined['Description'] = combined['Description_bank'].fillna(combined['Description_other'])\n",
        "    combined['Amount'] = combined['Amount_bank'].fillna(combined['Amount_other'])\n",
        "    combined['Balance'] = combined['Balance_bank'].fillna(combined['Balance_other']) # Note: Balance from bank is actual balance, from mpesa is running balance, bills is None\n",
        "    # Source_Type is merged 'on' so it should be fine\n",
        "\n",
        "    # Drop the original suffixed columns\n",
        "    combined.drop(columns=['Description_other', 'Description_bank', 'Amount_other', 'Amount_bank', 'Balance_other', 'Balance_bank'], errors='ignore', inplace=True)\n",
        "\n",
        "else:\n",
        "    # If bank_clean_merge was empty, combined is just merged_initial\n",
        "    combined = merged_initial.copy()\n",
        "    print(\"Warning: Bank data is empty. Combined dataframe contains only MPESA and Utility Bill data.\")\n",
        "\n",
        "\n",
        "# ✅ Step 10: Save Final Dataset\n",
        "# Sort by date if a consolidated date column exists or is created\n",
        "if 'Date' in combined.columns:\n",
        "    combined = combined.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# For now, let's save the combined dataframe as is, assuming the merge ran.\n",
        "if not combined.empty:\n",
        "    combined.to_csv('/content/combined_financial_data.csv', index=False)\n",
        "    print(\"✅ Combined data saved to '/content/combined_financial_data.csv'\")\n",
        "    print(\"\\nCombined DataFrame head:\")\n",
        "    display(combined.head())\n",
        "    print(\"\\nCombined DataFrame columns:\")\n",
        "    print(combined.columns.tolist())\n",
        "else:\n",
        "     print(\"Error: Combined DataFrame is empty after processing.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nVAM39-iItA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7978095b",
        "outputId": "35937bdd-5301-4197-bd38-a2a522e2d589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Extracted Text from First PDF ---\n",
            "Bank Statement\n",
            "2024\n",
            "Bank Statement\n",
            "Account Statement for Esther Wambui\n",
            "Account Number: 7890-1234-5678-9012\n",
            "Period: 01/01/2024 to 31/12/2024\n",
            "Branch: Eldoret\n",
            "Currency: KES\n",
            "Date\n",
            "Description\n",
            "Details\n",
            "Debit\n",
            "(KES)\n",
            "Credit\n",
            "(KES)\n",
            "Balance\n",
            "(KES)\n",
            "01/01/2024\n",
            "Opening Balance\n",
            "7,000.00\n",
            "05/01/2024\n",
            "Salary Credit\n",
            "Hospital Salary\n",
            "60,000.00\n",
            "67,000.00\n",
            "10/01/2024\n",
            "M-Pesa Paybill\n",
            "Rent\n",
            "18,000.00\n",
            "49,000.00\n",
            "15/01/2024\n",
            "Loan Repayment\n",
            "Mobile Loan\n",
            "4,000.00\n",
            "45,000.00\n",
            "20/01/2024\n",
            "Savings Transfer\n",
            "Savings A/C\n",
            "5,000.00\n",
            "40,000.00\n",
            "10/02/2024\n",
            "Salary Credit\n",
            "Delayed Salary\n",
            "60,000.00\n",
            "100,000.00\n",
            "05/05/2024\n",
            "M-Pesa Paybill\n",
            "Medical Training\n",
            "15,000.00\n",
            "85,000.00\n",
            "10/05/2024\n",
            "M-Pesa Transfer\n",
            "Side Hustle\n",
            "10,000.00\n",
            "95,000.00\n",
            "15/05/2024\n",
            "M-Pesa Transfer\n",
            "Unexplained Payment\n",
            "20,000.00\n",
            "75,000.00\n",
            "20/05/2024\n",
            "Savings Reversal\n",
            "Cash Need\n",
            "5,000.00\n",
            "80,000.00\n",
            "31/12/2024\n",
            "Closing Balance\n",
            "80,000.00\n",
            "1 of 1\n",
            "\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import fitz # PyMuPDF\n",
        "import os\n",
        "\n",
        "# Correcting the extraction path to match where the files were unzipped\n",
        "extract_path = \"/content/unzipped_pdfs\"\n",
        "\n",
        "# Find the first PDF file in the extracted directory\n",
        "pdf_files = [f for f in os.listdir(extract_path) if f.endswith(\".pdf\")]\n",
        "\n",
        "if pdf_files:\n",
        "    first_pdf_path = os.path.join(extract_path, pdf_files[0])\n",
        "    doc = fitz.open(first_pdf_path)\n",
        "    text = doc[0].get_text()\n",
        "    print(\"--- Extracted Text from First PDF ---\")\n",
        "    print(text)\n",
        "    print(\"-------------------------------------\")\n",
        "else:\n",
        "    print(f\"No PDF files found in {extract_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_h0TcC3OJMqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22YBchDBsV57",
        "outputId": "81e84432-8029-42c0-8bc9-cf544ed47cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDFs ready for parsing:\n",
            " - Statements (7).pdf\n",
            " - Statements (9).pdf\n",
            " - Statements (8).pdf\n",
            " - Statements (10).pdf\n",
            " - Statements (3).pdf\n",
            " - Statements (5).pdf\n",
            " - Statements (6).pdf\n",
            " - Statements (1).pdf\n",
            " - Statements (4).pdf\n",
            " - Statements (2).pdf\n",
            "\n",
            "Merged data saved as merged_data_output.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# File paths\n",
        "zip_path = 'fwdmockbankstatements.zip'\n",
        "csv1_path = 'synthetic_mpesa_transactions.csv'\n",
        "csv2_path = 'utility_bills_with_mpesa.csv'\n",
        "extract_dir = 'unzipped_statements'\n",
        "\n",
        "# 1. Extract ZIP\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# 2. Load CSVs\n",
        "mpesa_df = pd.read_csv(csv1_path)\n",
        "bills_df = pd.read_csv(csv2_path)\n",
        "\n",
        "# 3. Clean CSVs\n",
        "mpesa_df.drop_duplicates(inplace=True)\n",
        "bills_df.dropna(subset=['Final_Amount_KSh'], inplace=True)\n",
        "\n",
        "# 4. Merge\n",
        "common_cols = list(set(mpesa_df.columns) & set(bills_df.columns))\n",
        "if common_cols:\n",
        "    merged_df = pd.merge(mpesa_df, bills_df, on=common_cols[0], how='outer')\n",
        "else:\n",
        "    merged_df = pd.concat([mpesa_df, bills_df], axis=0)\n",
        "\n",
        "# 5. Show PDF file names\n",
        "pdf_files = list(Path(extract_dir).glob('*.pdf'))\n",
        "print(\"PDFs ready for parsing:\")\n",
        "for f in pdf_files:\n",
        "    print(\" -\", f.name)\n",
        "\n",
        "# 6. Save merged result\n",
        "merged_df.to_csv(\"merged_data_output.csv\", index=False)\n",
        "print(\"\\nMerged data saved as merged_data_output.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hu0jnIXVKFOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "Oa0ecJrOt0JW",
        "outputId": "039a4d58-67cd-41a5-fc93-8b6e2d548a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Warning: No transactions extracted for account 7890-1234-5678-9012.\n",
            "Warning: No transactions extracted for account 5678-9012-3456-7890.\n",
            "Warning: No transactions extracted for account 6789-0123-4567-8901.\n",
            "Warning: No transactions extracted for account 4567-8901-2345-6789.\n",
            "Warning: No transactions extracted for account 3456-7890-1234-5678.\n",
            "Warning: No transactions extracted for account 9012-3456-7890-1234.\n",
            "Warning: No transactions extracted for account 8901-2345-6789-0123.\n",
            "Warning: No transactions extracted for account 2345-6789-0123-4567.\n",
            "Warning: No transactions extracted for account 0123-4567-8901-2345.\n",
            "Warning: No transactions extracted for account 1234-5678-9012-3456.\n",
            "Warning: No transactions extracted for account 7890-1234-5678-9012.\n",
            "Warning: No transactions extracted for account 5678-9012-3456-7890.\n",
            "Warning: No transactions extracted for account 6789-0123-4567-8901.\n",
            "Warning: No transactions extracted for account 4567-8901-2345-6789.\n",
            "Warning: No transactions extracted for account 3456-7890-1234-5678.\n",
            "Warning: No transactions extracted for account 9012-3456-7890-1234.\n",
            "Warning: No transactions extracted for account 8901-2345-6789-0123.\n",
            "Warning: No transactions extracted for account 2345-6789-0123-4567.\n",
            "Warning: No transactions extracted for account 0123-4567-8901-2345.\n",
            "Warning: No transactions extracted for account 1234-5678-9012-3456.\n",
            "Warning: bank_df is empty. PDF parsing may have failed.\n",
            "Warning: bank_clean_merge is empty as bank_df was empty.\n",
            "✅ Combined data saved to '/content/combined_financial_data.csv'\n",
            "\n",
            "Combined DataFrame head:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-709660396.py:195: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  merged_initial = pd.concat([mpesa_clean, bills_clean], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Account_Number                Date Description  Amount  Balance Source_Type\n",
              "0         USER_9 2025-07-01 00:00:00    Pay Bill     0.0   1000.0       MPESA\n",
              "1        USER_10 2025-07-01 00:02:00    Withdraw     0.0   1000.0       MPESA\n",
              "2        USER_10 2025-07-01 00:04:00    Withdraw     0.0   1000.0       MPESA\n",
              "3         USER_7 2025-07-01 00:04:00  Send Money     0.0   1000.0       MPESA\n",
              "4         USER_4 2025-07-01 00:06:00     Deposit     0.0   1000.0       MPESA"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9404b8a3-dead-4979-8ac2-46ee04559560\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Account_Number</th>\n",
              "      <th>Date</th>\n",
              "      <th>Description</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Balance</th>\n",
              "      <th>Source_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>USER_9</td>\n",
              "      <td>2025-07-01 00:00:00</td>\n",
              "      <td>Pay Bill</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>MPESA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>USER_10</td>\n",
              "      <td>2025-07-01 00:02:00</td>\n",
              "      <td>Withdraw</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>MPESA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>USER_10</td>\n",
              "      <td>2025-07-01 00:04:00</td>\n",
              "      <td>Withdraw</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>MPESA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>USER_7</td>\n",
              "      <td>2025-07-01 00:04:00</td>\n",
              "      <td>Send Money</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>MPESA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>USER_4</td>\n",
              "      <td>2025-07-01 00:06:00</td>\n",
              "      <td>Deposit</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>MPESA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9404b8a3-dead-4979-8ac2-46ee04559560')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9404b8a3-dead-4979-8ac2-46ee04559560 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9404b8a3-dead-4979-8ac2-46ee04559560');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7620a56f-28bd-42c5-905b-30fc16fcd070\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7620a56f-28bd-42c5-905b-30fc16fcd070')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7620a56f-28bd-42c5-905b-30fc16fcd070 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"     print(\\\"Error: Combined DataFrame is empty\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Account_Number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"USER_10\",\n          \"USER_4\",\n          \"USER_9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-07-01 00:00:00\",\n        \"max\": \"2025-07-01 00:06:00\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2025-07-01 00:02:00\",\n          \"2025-07-01 00:06:00\",\n          \"2025-07-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Withdraw\",\n          \"Deposit\",\n          \"Pay Bill\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1000.0,\n        \"max\": 1000.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"MPESA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined DataFrame columns:\n",
            "['Account_Number', 'Date', 'Description', 'Amount', 'Balance', 'Source_Type']\n"
          ]
        }
      ],
      "source": [
        "# 🛠️ Step 1: Install Required Libraries\n",
        "!pip install pandas PyMuPDF\n",
        "\n",
        "# 📦 Step 2: Import Libraries\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "import fitz  # PyMuPDF for PDF parsing\n",
        "\n",
        "# 📁 Step 3: Mount Google Drive (if your files are there)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# 📂 Step 4: Set Paths to Your Files (update if needed)\n",
        "mpesa_csv = '/content/synthetic_mpesa_transactions.csv'\n",
        "bills_csv = '/content/utility_bills_with_mpesa.csv'\n",
        "bank_zip = '/content/fwdmockbankstatements.zip'\n",
        "extract_dir = '/content/unzipped_pdfs'\n",
        "\n",
        "# 📤 Step 5: Extract Bank Statements from ZIP\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(bank_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# ✅ Step 6: Clean MPESA Transactions\n",
        "mpesa = pd.read_csv(mpesa_csv)\n",
        "mpesa.drop_duplicates(inplace=True)\n",
        "# Removed string operations from numeric columns\n",
        "mpesa['Transaction_Amount'] = mpesa['Transaction_Amount'].replace('[^\\d.]', '', regex=True).astype(float)\n",
        "mpesa['Balance'] = mpesa['Balance'].replace('[^\\d.]', '', regex=True).astype(float)\n",
        "# Removed string operation from Wallet_Impact\n",
        "# mpesa['Wallet_Impact'] = mpesa['Wallet_Impact'].str.lower().str.strip() # Wallet_Impact is numeric\n",
        "mpesa['Date'] = pd.to_datetime(mpesa['Date'], errors='coerce')\n",
        "mpesa['Source_Type'] = 'MPESA'\n",
        "# Rename 'Account' to 'Account_Number' for consistency before merging\n",
        "if 'Account' in mpesa.columns:\n",
        "    mpesa.rename(columns={\"Account\": \"Account_Number\"}, inplace=True)\n",
        "\n",
        "\n",
        "# ✅ Step 7: Clean Utility Bills\n",
        "bills = pd.read_csv(bills_csv)\n",
        "bills.dropna(subset=['Final_Amount_KSh'], inplace=True)\n",
        "bills['Final_Amount_KSh'] = bills['Final_Amount_KSh'].replace('[^\\d.]', '', regex=True).astype(float)\n",
        "# Assuming 'Provider' column is intended as the description and is string type\n",
        "if 'Provider' in bills.columns:\n",
        "    # bills['Bill_Type'] = bills['Bill_Type'].str.lower().str.strip() # Renamed to Description below\n",
        "    bills.rename(columns={'Provider': 'Description'}, inplace=True) # Renaming Provider to Description\n",
        "    if pd.api.types.is_object_dtype(bills['Description']) or pd.api.types.is_string_dtype(bills['Description']):\n",
        "         bills['Description'] = bills['Description'].str.lower().str.strip()\n",
        "    else:\n",
        "         print(\"Warning: 'Description' column in utility bills is not a string type. Skipping string cleaning.\")\n",
        "\n",
        "bills['Date'] = pd.to_datetime(bills['Billing_Date'], errors='coerce') # Using Billing_Date as the Date for utility bills\n",
        "# Assuming Balance_After is not present or needs to be calculated later\n",
        "# bills.rename(columns={'Final_Amount_KSh': 'Amount', 'Balance_After': 'Balance', 'Bill_Type': 'Description'}, inplace=True)\n",
        "bills.rename(columns={'Final_Amount_KSh': 'Amount'}, inplace=True)\n",
        "bills['Source_Type'] = 'UTILITY_BILL'\n",
        "# Rename 'User_ID' to 'Account_Number' for consistency before merging\n",
        "if 'User_ID' in bills.columns:\n",
        "    bills.rename(columns={\"User_ID\": \"Account_Number\"}, inplace=True)\n",
        "\n",
        "\n",
        "# ✅ Step 8: Parse Bank PDFs (Using the corrected parsing logic from BWA3Kxh_ZOl0)\n",
        "# Note: The parse_pdf_bank_statements function needs to be defined or copied here\n",
        "# to be used within this cell if you want to run this cell independently after fixing parsing.\n",
        "# For now, we'll assume the improved_parse_bank_statement_text from BWA3Kxh_ZOl0 is available and working.\n",
        "\n",
        "# Replicating the parsing loop from BWA3Kxh_ZOl0 here for a self-contained cell\n",
        "# This assumes improved_parse_bank_statement_text is defined above this point or in an earlier cell\n",
        "all_data = []\n",
        "if os.path.exists(extract_dir):\n",
        "    for fname in os.listdir(extract_dir):\n",
        "        if fname.endswith(\".pdf\"):\n",
        "            doc_path = os.path.join(extract_dir, fname)\n",
        "            try:\n",
        "                doc = fitz.open(doc_path)\n",
        "                text = \"\"\n",
        "                for page in doc:\n",
        "                    text += page.get_text()\n",
        "                # Assuming improved_parse_bank_statement_text takes text as input and returns a DataFrame\n",
        "                # Make sure this function is defined and correctly extracts Account_Number\n",
        "                df = improved_parse_bank_statement_text(text) # Need to pass account number if extracted separately\n",
        "                if not df.empty:\n",
        "                    all_data.append(df)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {fname}: {e}\")\n",
        "\n",
        "\n",
        "# If parsing logic needs account number from header separately and not returned in df:\n",
        "# You might need to adjust improved_parse_bank_statement_text to return account_number as well\n",
        "# Or re-extract account number here and add to df\n",
        "\n",
        "# Re-parsing approach to ensure account number is added if not done by the function\n",
        "bank_transactions_list = []\n",
        "if os.path.exists(extract_dir):\n",
        "     for fname in os.listdir(extract_dir):\n",
        "         if fname.endswith(\".pdf\"):\n",
        "             doc_path = os.path.join(extract_dir, fname)\n",
        "             try:\n",
        "                 doc = fitz.open(doc_path)\n",
        "                 text = \"\"\n",
        "                 for page in doc:\n",
        "                     text += page.get_text()\n",
        "\n",
        "                 # Extract Account Number from header first\n",
        "                 acct_match = re.search(r'Account Number:\\s*([\\d\\-]+)', text)\n",
        "                 account_number = acct_match.group(1).strip() if acct_match else \"Unknown\"\n",
        "\n",
        "                 # Parse transactions, the function should ideally return transaction details without account number\n",
        "                 # Or you modify the function to include account number\n",
        "                 # Let's assume improved_parse_bank_statement_text parses rows and you add account_number here\n",
        "                 # This requires modifying improved_parse_bank_statement_text to return a list of transaction dicts or similar\n",
        "                 # instead of a DataFrame if account number is added outside.\n",
        "                 # A better approach is to modify the function itself to include account_number.\n",
        "\n",
        "                 # Assuming improved_parse_bank_statement_text is modified to return a DataFrame with Account_Number\n",
        "                 df = improved_parse_bank_statement_text(text)\n",
        "                 if not df.empty:\n",
        "                      bank_transactions_list.append(df)\n",
        "\n",
        "             except Exception as e:\n",
        "                 print(f\"Error processing {fname}: {e}\")\n",
        "\n",
        "\n",
        "if bank_transactions_list:\n",
        "    bank_df = pd.concat(bank_transactions_list, ignore_index=True)\n",
        "    bank_df['Source_Type'] = 'BANK_STATEMENT'\n",
        "    # Ensure 'Date' column in bank_df is datetime\n",
        "    if 'Date' in bank_df.columns and not pd.api.types.is_datetime64_any_dtype(bank_df['Date']):\n",
        "        bank_df['Date'] = pd.to_datetime(bank_df['Date'], errors='coerce').dt.date # Keep as date objects for consistency with utility bills initially\n",
        "\n",
        "    # Rename 'Account_Number' if the parsing function created a different name\n",
        "    # if 'Account_Number' not in bank_df.columns and 'Parsed_Account' in bank_df.columns:\n",
        "    #      bank_df.rename(columns={'Parsed_Account': 'Account_Number'}, inplace=True)\n",
        "\n",
        "else:\n",
        "    bank_df = pd.DataFrame()\n",
        "    print(\"Warning: bank_df is empty. PDF parsing may have failed.\")\n",
        "\n",
        "\n",
        "# ✅ Step 9: Combine All Sources\n",
        "\n",
        "# Ensure common columns exist and have appropriate names before merging\n",
        "common_cols_initial = ['Account_Number', 'Date', 'Description', 'Amount', 'Balance', 'Source_Type']\n",
        "\n",
        "# Select and rename columns for merging\n",
        "mpesa_clean = mpesa[mpesa.columns.intersection(['Account_Number', 'Date', 'Transaction_Type', 'Transaction_Amount', 'Balance', 'Source_Type'])].copy()\n",
        "mpesa_clean.rename(columns={'Transaction_Type': 'Description', 'Transaction_Amount': 'Amount'}, inplace=True)\n",
        "mpesa_clean = mpesa_clean[common_cols_initial].copy() # Reindex to ensure consistent column order and drop extras\n",
        "\n",
        "\n",
        "bills_clean = bills[bills.columns.intersection(['Account_Number', 'Date', 'Description', 'Amount', 'Source_Type'])].copy()\n",
        "# Bills data doesn't have a 'Balance' column directly equivalent to account balance\n",
        "bills_clean['Balance'] = None # Add a placeholder Balance column\n",
        "bills_clean = bills_clean[common_cols_initial].copy() # Reindex\n",
        "\n",
        "\n",
        "# Ensure bank_df has the expected columns if populated\n",
        "if not bank_df.empty:\n",
        "    bank_clean = bank_df[bank_df.columns.intersection(['Account_Number', 'Date', 'Description', 'Debit', 'Credit', 'Balance', 'Source_Type'])].copy()\n",
        "    # Decide how to represent Debit/Credit as a single 'Amount' for merging if needed, or keep separate\n",
        "    # For initial merge, let's keep Debit/Credit separate and 'Amount' from others.\n",
        "    # We'll need to align these later or use a different merge strategy.\n",
        "\n",
        "    # Option 1: Create 'Amount' from Debit/Credit (simplistic, might lose info)\n",
        "    # bank_clean['Amount'] = bank_clean['Credit'].fillna(0) - bank_clean['Debit'].fillna(0) # Or just use Credit as income, Debit as expense\n",
        "\n",
        "    # Option 2: Keep Debit/Credit separate and handle during feature engineering\n",
        "    # For merging, we might only need Account_Number and Date\n",
        "    # Let's proceed with merging on Account_Number and Date where possible\n",
        "\n",
        "    # Select columns for bank_clean for merging\n",
        "    bank_clean_merge = bank_df[bank_df.columns.intersection(['Account_Number', 'Date', 'Source_Type', 'Debit', 'Credit', 'Balance', 'Description'])].copy()\n",
        "    # Ensure Date is datetime for merging\n",
        "    if 'Date' in bank_clean_merge.columns and not pd.api.types.is_datetime64_any_dtype(bank_clean_merge['Date']):\n",
        "         bank_clean_merge['Date'] = pd.to_datetime(bank_clean_merge['Date'], errors='coerce')\n",
        "    # Ensure Account_Number exists\n",
        "    if 'Account_Number' not in bank_clean_merge.columns:\n",
        "         print(\"Error: 'Account_Number' column is missing in bank_clean_merge. Cannot merge.\")\n",
        "         bank_clean_merge = pd.DataFrame() # Make it empty to prevent merge errors\n",
        "\n",
        "else:\n",
        "    bank_clean_merge = pd.DataFrame()\n",
        "    print(\"Warning: bank_clean_merge is empty as bank_df was empty.\")\n",
        "\n",
        "\n",
        "# Perform Merges\n",
        "# Start by merging mpesa and bills on Account_Number and Date\n",
        "# Note: This merge strategy might not be ideal if timestamps don't match exactly.\n",
        "# Consider merging on Account_Number and then handling time-based relationships during feature engineering.\n",
        "\n",
        "# Let's try merging on Account_Number first, then handle time relationships later.\n",
        "merged_initial = pd.concat([mpesa_clean, bills_clean], ignore_index=True)\n",
        "\n",
        "# Now merge with bank data. This is tricky due to different structures (Debit/Credit vs single Amount)\n",
        "# A full outer merge on Account_Number seems appropriate to keep all records.\n",
        "# We'll use suffixes to distinguish columns.\n",
        "\n",
        "if not bank_clean_merge.empty:\n",
        "    combined = pd.merge(merged_initial, bank_clean_merge, on='Account_Number', how='outer', suffixes=('_other', '_bank'))\n",
        "else:\n",
        "    combined = merged_initial.copy() # If bank_df is empty, just use mpesa and bills data\n",
        "\n",
        "\n",
        "# Handle Date column: Consolidate dates if possible, or keep separate and handle during analysis\n",
        "# This part needs careful consideration based on how you want to use date information.\n",
        "# For simplicity for now, let's assume we have Date_other and Date_bank and handle them later.\n",
        "\n",
        "# ✅ Step 10: Save Final Dataset\n",
        "# Fill NaN values created by outer merge (optional, decide based on analysis needs)\n",
        "# combined.fillna(0, inplace=True) # Be cautious with filling dates or specific columns with 0\n",
        "\n",
        "# Sort by date if a consolidated date column exists or is created\n",
        "# If using Date_other and Date_bank, you might need a different sorting strategy or handle time in feature engineering.\n",
        "\n",
        "# For now, let's save the combined dataframe as is, assuming the merge ran.\n",
        "if not combined.empty:\n",
        "    combined.to_csv('/content/combined_financial_data.csv', index=False)\n",
        "    print(\"✅ Combined data saved to '/content/combined_financial_data.csv'\")\n",
        "    print(\"\\nCombined DataFrame head:\")\n",
        "    display(combined.head())\n",
        "    print(\"\\nCombined DataFrame columns:\")\n",
        "    print(combined.columns.tolist())\n",
        "else:\n",
        "     print(\"Error: Combined DataFrame is empty. Merging failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "77IhpWM1KX53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "outputId": "411fec83-3046-4dc5-b7f2-1373a5c5b103",
        "id": "YJSW1FJKKYU-"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Warning: No transactions extracted for account 7890-1234-5678-9012.\n",
            "Warning: No transactions extracted for account 5678-9012-3456-7890.\n",
            "Warning: No transactions extracted for account 6789-0123-4567-8901.\n",
            "Warning: No transactions extracted for account 4567-8901-2345-6789.\n",
            "Warning: No transactions extracted for account 3456-7890-1234-5678.\n",
            "Warning: No transactions extracted for account 9012-3456-7890-1234.\n",
            "Warning: No transactions extracted for account 8901-2345-6789-0123.\n",
            "Warning: No transactions extracted for account 2345-6789-0123-4567.\n",
            "Warning: No transactions extracted for account 0123-4567-8901-2345.\n",
            "Warning: No transactions extracted for account 1234-5678-9012-3456.\n",
            "Warning: No transactions extracted for account 7890-1234-5678-9012.\n",
            "Warning: No transactions extracted for account 5678-9012-3456-7890.\n",
            "Warning: No transactions extracted for account 6789-0123-4567-8901.\n",
            "Warning: No transactions extracted for account 4567-8901-2345-6789.\n",
            "Warning: No transactions extracted for account 3456-7890-1234-5678.\n",
            "Warning: No transactions extracted for account 9012-3456-7890-1234.\n",
            "Warning: No transactions extracted for account 8901-2345-6789-0123.\n",
            "Warning: No transactions extracted for account 2345-6789-0123-4567.\n",
            "Warning: No transactions extracted for account 0123-4567-8901-2345.\n",
            "Warning: No transactions extracted for account 1234-5678-9012-3456.\n",
            "Warning: bank_df is empty. PDF parsing may have failed.\n",
            "Warning: bank_clean_merge is empty as bank_df was empty.\n",
            "✅ Combined data saved to '/content/combined_financial_data.csv'\n",
            "\n",
            "Combined DataFrame head:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-709660396.py:195: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  merged_initial = pd.concat([mpesa_clean, bills_clean], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Account_Number                Date Description  Amount  Balance Source_Type\n",
              "0         USER_9 2025-07-01 00:00:00    Pay Bill     0.0   1000.0       MPESA\n",
              "1        USER_10 2025-07-01 00:02:00    Withdraw     0.0   1000.0       MPESA\n",
              "2        USER_10 2025-07-01 00:04:00    Withdraw     0.0   1000.0       MPESA\n",
              "3         USER_7 2025-07-01 00:04:00  Send Money     0.0   1000.0       MPESA\n",
              "4         USER_4 2025-07-01 00:06:00     Deposit     0.0   1000.0       MPESA"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b19536d6-1651-4fc6-a5d6-2d21480946a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Account_Number</th>\n",
              "      <th>Date</th>\n",
              "      <th>Description</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Balance</th>\n",
              "      <th>Source_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>USER_9</td>\n",
              "      <td>2025-07-01 00:00:00</td>\n",
              "      <td>Pay Bill</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>MPESA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>USER_10</td>\n",
              "      <td>2025-07-01 00:02:00</td>\n",
              "      <td>Withdraw</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>MPESA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>USER_10</td>\n",
              "      <td>2025-07-01 00:04:00</td>\n",
              "      <td>Withdraw</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>MPESA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>USER_7</td>\n",
              "      <td>2025-07-01 00:04:00</td>\n",
              "      <td>Send Money</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>MPESA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>USER_4</td>\n",
              "      <td>2025-07-01 00:06:00</td>\n",
              "      <td>Deposit</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>MPESA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b19536d6-1651-4fc6-a5d6-2d21480946a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b19536d6-1651-4fc6-a5d6-2d21480946a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b19536d6-1651-4fc6-a5d6-2d21480946a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e59e53f1-8cec-40fb-af3d-770a538dbde3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e59e53f1-8cec-40fb-af3d-770a538dbde3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e59e53f1-8cec-40fb-af3d-770a538dbde3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"     print(\\\"Error: Combined DataFrame is empty\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Account_Number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"USER_10\",\n          \"USER_4\",\n          \"USER_9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-07-01 00:00:00\",\n        \"max\": \"2025-07-01 00:06:00\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2025-07-01 00:02:00\",\n          \"2025-07-01 00:06:00\",\n          \"2025-07-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Withdraw\",\n          \"Deposit\",\n          \"Pay Bill\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1000.0,\n        \"max\": 1000.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Source_Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"MPESA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined DataFrame columns:\n",
            "['Account_Number', 'Date', 'Description', 'Amount', 'Balance', 'Source_Type']\n"
          ]
        }
      ],
      "source": [
        "# 🛠️ Step 1: Install Required Libraries\n",
        "!pip install pandas PyMuPDF\n",
        "\n",
        "# 📦 Step 2: Import Libraries\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "import fitz  # PyMuPDF for PDF parsing\n",
        "\n",
        "# 📁 Step 3: Mount Google Drive (if your files are there)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# 📂 Step 4: Set Paths to Your Files (update if needed)\n",
        "mpesa_csv = '/content/synthetic_mpesa_transactions.csv'\n",
        "bills_csv = '/content/utility_bills_with_mpesa.csv'\n",
        "bank_zip = '/content/fwdmockbankstatements.zip'\n",
        "extract_dir = '/content/unzipped_pdfs'\n",
        "\n",
        "# 📤 Step 5: Extract Bank Statements from ZIP\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(bank_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# ✅ Step 6: Clean MPESA Transactions\n",
        "mpesa = pd.read_csv(mpesa_csv)\n",
        "mpesa.drop_duplicates(inplace=True)\n",
        "# Removed string operations from numeric columns\n",
        "mpesa['Transaction_Amount'] = mpesa['Transaction_Amount'].replace('[^\\d.]', '', regex=True).astype(float)\n",
        "mpesa['Balance'] = mpesa['Balance'].replace('[^\\d.]', '', regex=True).astype(float)\n",
        "# Removed string operation from Wallet_Impact\n",
        "# mpesa['Wallet_Impact'] = mpesa['Wallet_Impact'].str.lower().str.strip() # Wallet_Impact is numeric\n",
        "mpesa['Date'] = pd.to_datetime(mpesa['Date'], errors='coerce')\n",
        "mpesa['Source_Type'] = 'MPESA'\n",
        "# Rename 'Account' to 'Account_Number' for consistency before merging\n",
        "if 'Account' in mpesa.columns:\n",
        "    mpesa.rename(columns={\"Account\": \"Account_Number\"}, inplace=True)\n",
        "\n",
        "\n",
        "# ✅ Step 7: Clean Utility Bills\n",
        "bills = pd.read_csv(bills_csv)\n",
        "bills.dropna(subset=['Final_Amount_KSh'], inplace=True)\n",
        "bills['Final_Amount_KSh'] = bills['Final_Amount_KSh'].replace('[^\\d.]', '', regex=True).astype(float)\n",
        "# Assuming 'Provider' column is intended as the description and is string type\n",
        "if 'Provider' in bills.columns:\n",
        "    # bills['Bill_Type'] = bills['Bill_Type'].str.lower().str.strip() # Renamed to Description below\n",
        "    bills.rename(columns={'Provider': 'Description'}, inplace=True) # Renaming Provider to Description\n",
        "    if pd.api.types.is_object_dtype(bills['Description']) or pd.api.types.is_string_dtype(bills['Description']):\n",
        "         bills['Description'] = bills['Description'].str.lower().str.strip()\n",
        "    else:\n",
        "         print(\"Warning: 'Description' column in utility bills is not a string type. Skipping string cleaning.\")\n",
        "\n",
        "bills['Date'] = pd.to_datetime(bills['Billing_Date'], errors='coerce') # Using Billing_Date as the Date for utility bills\n",
        "# Assuming Balance_After is not present or needs to be calculated later\n",
        "# bills.rename(columns={'Final_Amount_KSh': 'Amount', 'Balance_After': 'Balance', 'Bill_Type': 'Description'}, inplace=True)\n",
        "bills.rename(columns={'Final_Amount_KSh': 'Amount'}, inplace=True)\n",
        "bills['Source_Type'] = 'UTILITY_BILL'\n",
        "# Rename 'User_ID' to 'Account_Number' for consistency before merging\n",
        "if 'User_ID' in bills.columns:\n",
        "    bills.rename(columns={\"User_ID\": \"Account_Number\"}, inplace=True)\n",
        "\n",
        "\n",
        "# ✅ Step 8: Parse Bank PDFs (Using the corrected parsing logic from BWA3Kxh_ZOl0)\n",
        "# Note: The parse_pdf_bank_statements function needs to be defined or copied here\n",
        "# to be used within this cell if you want to run this cell independently after fixing parsing.\n",
        "# For now, we'll assume the improved_parse_bank_statement_text from BWA3Kxh_ZOl0 is available and working.\n",
        "\n",
        "# Replicating the parsing loop from BWA3Kxh_ZOl0 here for a self-contained cell\n",
        "# This assumes improved_parse_bank_statement_text is defined above this point or in an earlier cell\n",
        "all_data = []\n",
        "if os.path.exists(extract_dir):\n",
        "    for fname in os.listdir(extract_dir):\n",
        "        if fname.endswith(\".pdf\"):\n",
        "            doc_path = os.path.join(extract_dir, fname)\n",
        "            try:\n",
        "                doc = fitz.open(doc_path)\n",
        "                text = \"\"\n",
        "                for page in doc:\n",
        "                    text += page.get_text()\n",
        "                # Assuming improved_parse_bank_statement_text takes text as input and returns a DataFrame\n",
        "                # Make sure this function is defined and correctly extracts Account_Number\n",
        "                df = improved_parse_bank_statement_text(text) # Need to pass account number if extracted separately\n",
        "                if not df.empty:\n",
        "                    all_data.append(df)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {fname}: {e}\")\n",
        "\n",
        "\n",
        "# If parsing logic needs account number from header separately and not returned in df:\n",
        "# You might need to adjust improved_parse_bank_statement_text to return account_number as well\n",
        "# Or re-extract account number here and add to df\n",
        "\n",
        "# Re-parsing approach to ensure account number is added if not done by the function\n",
        "bank_transactions_list = []\n",
        "if os.path.exists(extract_dir):\n",
        "     for fname in os.listdir(extract_dir):\n",
        "         if fname.endswith(\".pdf\"):\n",
        "             doc_path = os.path.join(extract_dir, fname)\n",
        "             try:\n",
        "                 doc = fitz.open(doc_path)\n",
        "                 text = \"\"\n",
        "                 for page in doc:\n",
        "                     text += page.get_text()\n",
        "\n",
        "                 # Extract Account Number from header first\n",
        "                 acct_match = re.search(r'Account Number:\\s*([\\d\\-]+)', text)\n",
        "                 account_number = acct_match.group(1).strip() if acct_match else \"Unknown\"\n",
        "\n",
        "                 # Parse transactions, the function should ideally return transaction details without account number\n",
        "                 # Or you modify the function to include account number\n",
        "                 # Let's assume improved_parse_bank_statement_text parses rows and you add account_number here\n",
        "                 # This requires modifying improved_parse_bank_statement_text to return a list of transaction dicts or similar\n",
        "                 # instead of a DataFrame if account number is added outside.\n",
        "                 # A better approach is to modify the function itself to include account_number.\n",
        "\n",
        "                 # Assuming improved_parse_bank_statement_text is modified to return a DataFrame with Account_Number\n",
        "                 df = improved_parse_bank_statement_text(text)\n",
        "                 if not df.empty:\n",
        "                      bank_transactions_list.append(df)\n",
        "\n",
        "             except Exception as e:\n",
        "                 print(f\"Error processing {fname}: {e}\")\n",
        "\n",
        "\n",
        "if bank_transactions_list:\n",
        "    bank_df = pd.concat(bank_transactions_list, ignore_index=True)\n",
        "    bank_df['Source_Type'] = 'BANK_STATEMENT'\n",
        "    # Ensure 'Date' column in bank_df is datetime\n",
        "    if 'Date' in bank_df.columns and not pd.api.types.is_datetime64_any_dtype(bank_df['Date']):\n",
        "        bank_df['Date'] = pd.to_datetime(bank_df['Date'], errors='coerce').dt.date # Keep as date objects for consistency with utility bills initially\n",
        "\n",
        "    # Rename 'Account_Number' if the parsing function created a different name\n",
        "    # if 'Account_Number' not in bank_df.columns and 'Parsed_Account' in bank_df.columns:\n",
        "    #      bank_df.rename(columns={'Parsed_Account': 'Account_Number'}, inplace=True)\n",
        "\n",
        "else:\n",
        "    bank_df = pd.DataFrame()\n",
        "    print(\"Warning: bank_df is empty. PDF parsing may have failed.\")\n",
        "\n",
        "\n",
        "# ✅ Step 9: Combine All Sources\n",
        "\n",
        "# Ensure common columns exist and have appropriate names before merging\n",
        "common_cols_initial = ['Account_Number', 'Date', 'Description', 'Amount', 'Balance', 'Source_Type']\n",
        "\n",
        "# Select and rename columns for merging\n",
        "mpesa_clean = mpesa[mpesa.columns.intersection(['Account_Number', 'Date', 'Transaction_Type', 'Transaction_Amount', 'Balance', 'Source_Type'])].copy()\n",
        "mpesa_clean.rename(columns={'Transaction_Type': 'Description', 'Transaction_Amount': 'Amount'}, inplace=True)\n",
        "mpesa_clean = mpesa_clean[common_cols_initial].copy() # Reindex to ensure consistent column order and drop extras\n",
        "\n",
        "\n",
        "bills_clean = bills[bills.columns.intersection(['Account_Number', 'Date', 'Description', 'Amount', 'Source_Type'])].copy()\n",
        "# Bills data doesn't have a 'Balance' column directly equivalent to account balance\n",
        "bills_clean['Balance'] = None # Add a placeholder Balance column\n",
        "bills_clean = bills_clean[common_cols_initial].copy() # Reindex\n",
        "\n",
        "\n",
        "# Ensure bank_df has the expected columns if populated\n",
        "if not bank_df.empty:\n",
        "    bank_clean = bank_df[bank_df.columns.intersection(['Account_Number', 'Date', 'Description', 'Debit', 'Credit', 'Balance', 'Source_Type'])].copy()\n",
        "    # Decide how to represent Debit/Credit as a single 'Amount' for merging if needed, or keep separate\n",
        "    # For initial merge, let's keep Debit/Credit separate and 'Amount' from others.\n",
        "    # We'll need to align these later or use a different merge strategy.\n",
        "\n",
        "    # Option 1: Create 'Amount' from Debit/Credit (simplistic, might lose info)\n",
        "    # bank_clean['Amount'] = bank_clean['Credit'].fillna(0) - bank_clean['Debit'].fillna(0) # Or just use Credit as income, Debit as expense\n",
        "\n",
        "    # Option 2: Keep Debit/Credit separate and handle during feature engineering\n",
        "    # For merging, we might only need Account_Number and Date\n",
        "    # Let's proceed with merging on Account_Number and Date where possible\n",
        "\n",
        "    # Select columns for bank_clean for merging\n",
        "    bank_clean_merge = bank_df[bank_df.columns.intersection(['Account_Number', 'Date', 'Source_Type', 'Debit', 'Credit', 'Balance', 'Description'])].copy()\n",
        "    # Ensure Date is datetime for merging\n",
        "    if 'Date' in bank_clean_merge.columns and not pd.api.types.is_datetime64_any_dtype(bank_clean_merge['Date']):\n",
        "         bank_clean_merge['Date'] = pd.to_datetime(bank_clean_merge['Date'], errors='coerce')\n",
        "    # Ensure Account_Number exists\n",
        "    if 'Account_Number' not in bank_clean_merge.columns:\n",
        "         print(\"Error: 'Account_Number' column is missing in bank_clean_merge. Cannot merge.\")\n",
        "         bank_clean_merge = pd.DataFrame() # Make it empty to prevent merge errors\n",
        "\n",
        "else:\n",
        "    bank_clean_merge = pd.DataFrame()\n",
        "    print(\"Warning: bank_clean_merge is empty as bank_df was empty.\")\n",
        "\n",
        "\n",
        "# Perform Merges\n",
        "# Start by merging mpesa and bills on Account_Number and Date\n",
        "# Note: This merge strategy might not be ideal if timestamps don't match exactly.\n",
        "# Consider merging on Account_Number and then handling time-based relationships during feature engineering.\n",
        "\n",
        "# Let's try merging on Account_Number first, then handle time relationships later.\n",
        "merged_initial = pd.concat([mpesa_clean, bills_clean], ignore_index=True)\n",
        "\n",
        "# Now merge with bank data. This is tricky due to different structures (Debit/Credit vs single Amount)\n",
        "# A full outer merge on Account_Number seems appropriate to keep all records.\n",
        "# We'll use suffixes to distinguish columns.\n",
        "\n",
        "if not bank_clean_merge.empty:\n",
        "    combined = pd.merge(merged_initial, bank_clean_merge, on='Account_Number', how='outer', suffixes=('_other', '_bank'))\n",
        "else:\n",
        "    combined = merged_initial.copy() # If bank_df is empty, just use mpesa and bills data\n",
        "\n",
        "\n",
        "# Handle Date column: Consolidate dates if possible, or keep separate and handle during analysis\n",
        "# This part needs careful consideration based on how you want to use date information.\n",
        "# For simplicity for now, let's assume we have Date_other and Date_bank and handle them later.\n",
        "\n",
        "# ✅ Step 10: Save Final Dataset\n",
        "# Fill NaN values created by outer merge (optional, decide based on analysis needs)\n",
        "# combined.fillna(0, inplace=True) # Be cautious with filling dates or specific columns with 0\n",
        "\n",
        "# Sort by date if a consolidated date column exists or is created\n",
        "# If using Date_other and Date_bank, you might need a different sorting strategy or handle time in feature engineering.\n",
        "\n",
        "# For now, let's save the combined dataframe as is, assuming the merge ran.\n",
        "if not combined.empty:\n",
        "    combined.to_csv('/content/combined_financial_data.csv', index=False)\n",
        "    print(\"✅ Combined data saved to '/content/combined_financial_data.csv'\")\n",
        "    print(\"\\nCombined DataFrame head:\")\n",
        "    display(combined.head())\n",
        "    print(\"\\nCombined DataFrame columns:\")\n",
        "    print(combined.columns.tolist())\n",
        "else:\n",
        "     print(\"Error: Combined DataFrame is empty. Merging failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3NEtSR-Kk10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "JmG0EGcLy-uz",
        "outputId": "4825d60f-8fb2-4d8b-8d59-6bdbf823aa6d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-347974511.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Load the cleaned data\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv(\"cleaned_credit_data.csv\")\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df['Source_Type'] = LabelEncoder().fit_transform(df['Source_Type'])\n",
        "    df['Description'] = df['Description'].astype(str).str.lower()\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# Add a target column for demonstration\n",
        "if 'Risk_Label' not in df.columns:\n",
        "    df['Risk_Label'] = df['Balance'].apply(lambda x: 0 if x < 500 else 1)\n",
        "\n",
        "# Title\n",
        "st.title(\"HEVA Credit Intelligence Dashboard\")\n",
        "st.markdown(\"Analyze MPESA, Utility, and Bank data for credit scoring insights.\")\n",
        "\n",
        "# Sidebar filters\n",
        "st.sidebar.header(\"Filter Options\")\n",
        "source_filter = st.sidebar.multiselect(\"Select Source Type\", options=df['Source_Type'].unique(), default=df['Source_Type'].unique())\n",
        "amount_range = st.sidebar.slider(\"Transaction Amount Range\", float(df['Amount'].min()), float(df['Amount'].max()), (float(df['Amount'].min()), float(df['Amount'].max())))\n",
        "\n",
        "# Apply filters\n",
        "filtered_df = df[(df['Source_Type'].isin(source_filter)) &\n",
        "                 (df['Amount'] >= amount_range[0]) & (df['Amount'] <= amount_range[1])]\n",
        "\n",
        "# Show data sample\n",
        "st.subheader(\"Filtered Transactions\")\n",
        "st.dataframe(filtered_df.head(20))\n",
        "\n",
        "# Plot 1: Amount over time\n",
        "st.subheader(\"Transaction Amounts Over Time\")\n",
        "fig1, ax1 = plt.subplots()\n",
        "filtered_df.groupby('Date')['Amount'].sum().plot(ax=ax1)\n",
        "ax1.set_ylabel(\"Total Amount\")\n",
        "ax1.set_title(\"Daily Transaction Amounts\")\n",
        "st.pyplot(fig1)\n",
        "\n",
        "# Plot 2: Source Type Breakdown\n",
        "st.subheader(\"Transaction Source Breakdown\")\n",
        "fig2, ax2 = plt.subplots()\n",
        "sns.countplot(data=filtered_df, x='Source_Type', ax=ax2)\n",
        "ax2.set_title(\"Transactions by Source\")\n",
        "st.pyplot(fig2)\n",
        "\n",
        "# Summary stats\n",
        "st.subheader(\"Summary Statistics\")\n",
        "st.write(filtered_df.describe())\n",
        "\n",
        "# Credit Risk Predictor\n",
        "st.subheader(\"📊 Predict Credit Risk\")\n",
        "\n",
        "input_amount = st.number_input(\"Transaction Amount\", value=1000.0)\n",
        "input_balance = st.number_input(\"Account Balance\", value=500.0)\n",
        "input_source = st.selectbox(\"Source Type\", options=sorted(df['Source_Type'].unique()))\n",
        "\n",
        "if st.button(\"Predict Risk\"):\n",
        "    # Prepare model training\n",
        "    features = ['Amount', 'Balance', 'Source_Type']\n",
        "    X = df[features]\n",
        "    y = df['Risk_Label']\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Train model\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_scaled, y)\n",
        "\n",
        "    # Predict\n",
        "    user_input = pd.DataFrame([[input_amount, input_balance, input_source]], columns=features)\n",
        "    user_scaled = scaler.transform(user_input)\n",
        "    prediction = model.predict(user_scaled)[0]\n",
        "    prediction_proba = model.predict_proba(user_scaled)[0]\n",
        "\n",
        "    # Output result\n",
        "    st.markdown(f\"### Risk Prediction: {'🟢 Low Risk' if prediction == 1 else '🔴 High Risk'}\")\n",
        "    st.write(f\"Confidence: {round(np.max(prediction_proba)*100, 2)}%\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"Built with ❤️ by HEVA Credit Analytics\")\n"
      ]
    }
  ]
}